# -*- coding: utf-8 -*-
"""Face_detection_using _R-CNNipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11OuTRNrmqPnTgl4ndKEiVcrYMl4O7_9q

Data:https://app.roboflow.com/asad-0gqib/face-detection-mik1i-8sw7e/3/export

Install Dectectron2 Dependencies
"""

!pip install pyyaml==5.1
import torch, torchvision
print(torch.__version__, torch.cuda.is_available())

!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'

# some basic setup:
# setup detectron2 logger
import detectron2
from detectron2.utils.logger import setup_logger
setup_logger()

# import some common libraries
import numpy as np
import os, json, cv2, random
from google.colab.patches import cv2_imshow

#import some common detectron2 utilities
from detectron2 import model_zoo
from detectron2.engine import DefaultPredictor
from detectron2.config import get_cfg
from detectron2.utils.visualizer import Visualizer
from detectron2.data import MetadataCatalog, DatasetCatalog

"""Import and Register Custom Detectron2 Data"""

!pip install roboflow

from roboflow import Roboflow
rf = Roboflow(api_key="zkAeoiiZyALurrER47sL")
project = rf.workspace("asad-0gqib").project("face-detection-mik1i-8sw7e")
version = project.version(5)
dataset = version.download("coco")

#from atexit import register
from detectron2.data.datasets import register_coco_instances
from detectron2.data import DatasetCatalog, MetadataCatalog

# Unregister the datasets if they exist
for d in ["my_dataset_train", "my_dataset_test"]:
    if d in DatasetCatalog.list():
        DatasetCatalog.remove(d)
    if d in MetadataCatalog.list():
        MetadataCatalog.remove(d)

register_coco_instances("my_dataset_train", {}, "/content/Face-Detection-5/train/_annotations.coco.json", "/content/Face-Detection-5/train")
register_coco_instances("my_dataset_test", {}, "/content/Face-Detection-5/test/_annotations.coco.json", "/content/Face-Detection-5/test")

#vizualies training data

from google.colab.patches import cv2_imshow  # Only needed if you're using Google Colab

import cv2
import random
from detectron2.utils.visualizer import Visualizer
from detectron2.data import MetadataCatalog, DatasetCatalog

my_dataset_train_metadata = MetadataCatalog.get("my_dataset_train")
dataset_dicts = DatasetCatalog.get("my_dataset_train")

for d in random.sample(dataset_dicts, 20):
    img = cv2.imread(d["file_name"])
    visualizer = Visualizer(img[:, :, ::-1], metadata=my_dataset_train_metadata, scale=0.5)
    vis = visualizer.draw_dataset_dict(d)
    cv2_imshow(vis.get_image()[:, :, ::-1])  # <-- This line displays the image correctly

"""Traing:"""

from detectron2.engine import DefaultTrainer
from detectron2.config import get_cfg
from detectron2 import model_zoo
import os

cfg = get_cfg()
cfg.merge_from_file(model_zoo.get_config_file("COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml"))
cfg.DATASETS.TRAIN = ("my_dataset_train",)
cfg.DATASETS.TEST = ()
cfg.DATALOADER.NUM_WORKERS = 2
cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url("COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml")
cfg.SOLVER.IMS_PER_BATCH = 2
cfg.SOLVER.BASE_LR =0.0025 # pick a good
cfg.SOLVER.MAX_ITER = 300
cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128
cfg.MODEL.ROI_HEADS.NUM_CLASSES = 6
os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)
trainer = DefaultTrainer(cfg)
trainer.resume_or_load(resume=False)
trainer.train()

# Commented out IPython magic to ensure Python compatibility.
# Look at training curve in tensorborad

# %load_ext tensorboard
# %tensorboard --logdir output

cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, "model_final.pth")
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5 # threshold for this model
predictor = DefaultPredictor(cfg)

"""Inference With dectectron2 saved Weights"""

test_metadata = MetadataCatalog.get("my_dataset_test")
from detectron2.utils.visualizer import ColorMode

from detectron2.utils.visualizer import ColorMode
import glob
import cv2 # Import cv2 for imread and cv2_imshow

test_metadata = MetadataCatalog.get("my_dataset_test") # Define test_metadata

for imageName in glob.glob ('/content/Face-Detection-5/test/*.jpg'): # Correct glob pattern
  im = cv2.imread(imageName)
  outputs = predictor(im)
  v = Visualizer(im[:, :, ::-1], metadata=test_metadata, scale=0.5) # Add metadata and scale
  out = v.draw_instance_predictions(outputs["instances"].to("cpu"))
  cv2_imshow(out.get_image()[:, :, ::-1])  # <-- This line displays the image correctly

"""Evaluation"""

from detectron2.evaluation import COCOEvaluator, inference_on_dataset
from detectron2.data import build_detection_test_loader

evaluator = COCOEvaluator("my_dataset_test", cfg, False, output_dir="/content/output")
val_loader = build_detection_test_loader(cfg, "my_dataset_test")
results = inference_on_dataset(trainer.model, val_loader, evaluator)
print(results)